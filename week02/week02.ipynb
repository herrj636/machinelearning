{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a module with a class **SimpleRegression** that will fit and store attributes for ordinary least squares Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"img/reg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import my_module\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module my_module:\n",
      "\n",
      "NAME\n",
      "    my_module\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        SimpleRegression\n",
      "    \n",
      "    class SimpleRegression(builtins.object)\n",
      "     |  Fits OLS simple regression\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize attributes\n",
      "     |  \n",
      "     |  fit(self, X, Y)\n",
      "     |      Fit the OLS model\n",
      "     |  \n",
      "     |  get_a(self, X, Y)\n",
      "     |      Calculate the intercept\n",
      "     |  \n",
      "     |  get_b(self, X, Y)\n",
      "     |      Calculate the coefficient / slope\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Predict Y\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FILE\n",
      "    /Users/juandherrera/Google Drive/017_Machine Learning/ml/week02/my_module.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(my_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.datasets in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.datasets\n",
      "\n",
      "DESCRIPTION\n",
      "    The :mod:`sklearn.datasets` module includes utilities to load datasets,\n",
      "    including methods to load and fetch popular reference datasets. It also\n",
      "    features some artificial data generators.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _svmlight_format\n",
      "    base\n",
      "    california_housing\n",
      "    covtype\n",
      "    kddcup99\n",
      "    lfw\n",
      "    mlcomp\n",
      "    mldata\n",
      "    olivetti_faces\n",
      "    openml\n",
      "    rcv1\n",
      "    samples_generator\n",
      "    setup\n",
      "    species_distributions\n",
      "    svmlight_format\n",
      "    tests (package)\n",
      "    twenty_newsgroups\n",
      "\n",
      "FUNCTIONS\n",
      "    clear_data_home(data_home=None)\n",
      "        Delete all the content of the data home cache.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str | None\n",
      "            The path to scikit-learn data dir.\n",
      "    \n",
      "    dump_svmlight_file(X, y, f, zero_based=True, comment=None, query_id=None, multilabel=False)\n",
      "        Dump the dataset in svmlight / libsvm file format.\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      "            Training vectors, where n_samples is the number of samples and\n",
      "            n_features is the number of features.\n",
      "        \n",
      "        y : {array-like, sparse matrix}, shape = [n_samples (, n_labels)]\n",
      "            Target values. Class labels must be an\n",
      "            integer or float, or array-like objects of integer or float for\n",
      "            multilabel classifications.\n",
      "        \n",
      "        f : string or file-like in binary mode\n",
      "            If string, specifies the path that will contain the data.\n",
      "            If file-like, data will be written to f. f should be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        zero_based : boolean, optional\n",
      "            Whether column indices should be written zero-based (True) or one-based\n",
      "            (False).\n",
      "        \n",
      "        comment : string, optional\n",
      "            Comment to insert at the top of the file. This should be either a\n",
      "            Unicode string, which will be encoded as UTF-8, or an ASCII byte\n",
      "            string.\n",
      "            If a comment is given, then it will be preceded by one that identifies\n",
      "            the file as having been dumped by scikit-learn. Note that not all\n",
      "            tools grok comments in SVMlight files.\n",
      "        \n",
      "        query_id : array-like, shape = [n_samples]\n",
      "            Array containing pairwise preference constraints (qid in svmlight\n",
      "            format).\n",
      "        \n",
      "        multilabel : boolean, optional\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter *multilabel* to support multilabel datasets.\n",
      "    \n",
      "    fetch_20newsgroups(data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True)\n",
      "        Load the filenames and data from the 20 newsgroups dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality               1\n",
      "        Features                  text\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify a download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : 'train' or 'test', 'all', optional\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        categories : None or collection of string or unicode\n",
      "            If None (default), load all the categories.\n",
      "            If not None, list of category names to load (other categories\n",
      "            ignored).\n",
      "        \n",
      "        shuffle : bool, optional\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        remove : tuple\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "            'headers' follows an exact standard; the other filters are not always\n",
      "            correct.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : Bunch object\n",
      "            bunch.data: list, length [n_samples]\n",
      "            bunch.target: array, shape [n_samples]\n",
      "            bunch.filenames: list, length [n_classes]\n",
      "            bunch.DESCR: a description of the dataset.\n",
      "    \n",
      "    fetch_20newsgroups_vectorized(subset='train', remove=(), data_home=None, download_if_missing=True, return_X_y=False)\n",
      "        Load the 20 newsgroups dataset and vectorize it into token counts (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        This is a convenience function; the transformation is done using the\n",
      "        default settings for\n",
      "        :class:`sklearn.feature_extraction.text.CountVectorizer`. For more\n",
      "        advanced usage (stopword filtering, n-gram extraction, etc.), combine\n",
      "        fetch_20newsgroups with a custom\n",
      "        :class:`sklearn.feature_extraction.text.CountVectorizer`,\n",
      "        :class:`sklearn.feature_extraction.text.HashingVectorizer`,\n",
      "        :class:`sklearn.feature_extraction.text.TfidfTransformer` or\n",
      "        :class:`sklearn.feature_extraction.text.TfidfVectorizer`.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality          130107\n",
      "        Features                  real\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : 'train' or 'test', 'all', optional\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        remove : tuple\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "        data_home : optional, default: None\n",
      "            Specify an download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : Bunch object\n",
      "            bunch.data: sparse matrix, shape [n_samples, n_features]\n",
      "            bunch.target: array, shape [n_samples]\n",
      "            bunch.target_names: list, length [n_classes]\n",
      "            bunch.DESCR: a description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_california_housing(data_home=None, download_if_missing=True, return_X_y=False)\n",
      "        Load the California housing dataset (regression).\n",
      "        \n",
      "        ==============     ==============\n",
      "        Samples total               20640\n",
      "        Dimensionality                  8\n",
      "        Features                     real\n",
      "        Target             real 0.15 - 5.\n",
      "        ==============     ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <california_housing_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : optional, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : ndarray, shape [20640, 8]\n",
      "            Each row corresponding to the 8 feature values in order.\n",
      "        \n",
      "        dataset.target : numpy array of shape (20640,)\n",
      "            Each value corresponds to the average house value in units of 100,000.\n",
      "        \n",
      "        dataset.feature_names : array of length 8\n",
      "            Array of ordered feature names used in the dataset.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the California housing dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Notes\n",
      "        ------\n",
      "        \n",
      "        This dataset consists of 20,640 samples and 9 features.\n",
      "    \n",
      "    fetch_covtype(data_home=None, download_if_missing=True, random_state=None, shuffle=False, return_X_y=False)\n",
      "        Load the covertype dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ============\n",
      "        Classes                        7\n",
      "        Samples total             581012\n",
      "        Dimensionality                54\n",
      "        Features                     int\n",
      "        =================   ============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <covtype_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : string, optional\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : boolean, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : numpy array of shape (581012, 54)\n",
      "            Each row corresponds to the 54 features in the dataset.\n",
      "        \n",
      "        dataset.target : numpy array of shape (581012,)\n",
      "            Each value corresponds to one of the 7 forest covertypes with values\n",
      "            ranging between 1 to 7.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the forest covertype dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_kddcup99(subset=None, data_home=None, shuffle=False, random_state=None, percent10=True, download_if_missing=True, return_X_y=False)\n",
      "        Load the kddcup99 dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ====================================\n",
      "        Classes                                               23\n",
      "        Samples total                                    4898431\n",
      "        Dimensionality                                        41\n",
      "        Features            discrete (int) or continuous (float)\n",
      "        =================   ====================================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <kddcup99_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : None, 'SA', 'SF', 'http', 'smtp'\n",
      "            To return the corresponding classical subsets of kddcup 99.\n",
      "            If None, return the entire kddcup 99 dataset.\n",
      "        \n",
      "        data_home : string, optional\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling and for\n",
      "            selection of abnormal samples if `subset='SA'`. Pass an int for\n",
      "            reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        percent10 : bool, default=True\n",
      "            Whether to load only 10 percent of the data.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "             - 'data', the data to learn.\n",
      "             - 'target', the regression target for each sample.\n",
      "             - 'DESCR', a description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_lfw_pairs(subset='train', data_home=None, funneled=True, resize=0.5, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True)\n",
      "        Load the Labeled Faces in the Wild (LFW) pairs dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                5749\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        In the official `README.txt`_ this task is described as the\n",
      "        \"Restricted\" task.  As I am not sure as to implement the\n",
      "        \"Unrestricted\" variant correctly, I left it as unsupported for now.\n",
      "        \n",
      "          .. _`README.txt`: http://vis-www.cs.umass.edu/lfw/README.txt\n",
      "        \n",
      "        The original images are 250 x 250 pixels, but the default slice and resize\n",
      "        arguments reduce them to 62 x 47.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : optional, default: 'train'\n",
      "            Select the dataset to load: 'train' for the development training\n",
      "            set, 'test' for the development test set, and '10_folds' for the\n",
      "            official evaluation set that is meant to be used with a 10-folds\n",
      "            cross validation.\n",
      "        \n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By\n",
      "            default all scikit-learn data is stored in '~/scikit_learn_data'\n",
      "            subfolders.\n",
      "        \n",
      "        funneled : boolean, optional, default: True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, optional, default 0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        color : boolean, optional, default False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : optional\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        The data is returned as a Bunch object with the following attributes:\n",
      "        \n",
      "        data : numpy array of shape (2200, 5828). Shape depends on ``subset``.\n",
      "            Each row corresponds to 2 ravel'd face images of original size 62 x 47\n",
      "            pixels. Changing the ``slice_``, ``resize`` or ``subset`` parameters\n",
      "            will change the shape of the output.\n",
      "        \n",
      "        pairs : numpy array of shape (2200, 2, 62, 47). Shape depends on ``subset``\n",
      "            Each row has 2 face images corresponding to same or different person\n",
      "            from the dataset containing 5749 people. Changing the ``slice_``,\n",
      "            ``resize`` or ``subset`` parameters will change the shape of the\n",
      "            output.\n",
      "        \n",
      "        target : numpy array of shape (2200,). Shape depends on ``subset``.\n",
      "            Labels associated to each pair of images. The two label values being\n",
      "            different persons or the same person.\n",
      "        \n",
      "        DESCR : string\n",
      "            Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "    \n",
      "    fetch_lfw_people(data_home=None, funneled=True, resize=0.5, min_faces_per_person=0, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True, return_X_y=False)\n",
      "        Load the Labeled Faces in the Wild (LFW) people dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                5749\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        funneled : boolean, optional, default: True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, optional, default 0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        min_faces_per_person : int, optional, default None\n",
      "            The extracted dataset will only retain pictures of people that have at\n",
      "            least `min_faces_per_person` different pictures.\n",
      "        \n",
      "        color : boolean, optional, default False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : optional\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : numpy array of shape (13233, 2914)\n",
      "            Each row corresponds to a ravelled face image of original size 62 x 47\n",
      "            pixels. Changing the ``slice_`` or resize parameters will change the\n",
      "            shape of the output.\n",
      "        \n",
      "        dataset.images : numpy array of shape (13233, 62, 47)\n",
      "            Each row is a face image corresponding to one of the 5749 people in\n",
      "            the dataset. Changing the ``slice_`` or resize parameters will change\n",
      "            the shape of the output.\n",
      "        \n",
      "        dataset.target : numpy array of shape (13233,)\n",
      "            Labels associated to each face image. Those labels range from 0-5748\n",
      "            and correspond to the person IDs.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_mldata(dataname, target_name='label', data_name='data', transpose_data=True, data_home=None)\n",
      "        DEPRECATED: fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "        \n",
      "        Fetch an mldata.org data set\n",
      "        \n",
      "            mldata.org is no longer operational.\n",
      "        \n",
      "            If the file does not exist yet, it is downloaded from mldata.org .\n",
      "        \n",
      "            mldata.org does not have an enforced convention for storing data or\n",
      "            naming the columns in a data set. The default behavior of this function\n",
      "            works well with the most common cases:\n",
      "        \n",
      "              1) data values are stored in the column 'data', and target values in the\n",
      "                 column 'label'\n",
      "              2) alternatively, the first column stores target values, and the second\n",
      "                 data values\n",
      "              3) the data array is stored as `n_features x n_samples` , and thus needs\n",
      "                 to be transposed to match the `sklearn` standard\n",
      "        \n",
      "            Keyword arguments allow to adapt these defaults to specific data sets\n",
      "            (see parameters `target_name`, `data_name`, `transpose_data`, and\n",
      "            the examples below).\n",
      "        \n",
      "            mldata.org data sets may have multiple columns, which are stored in the\n",
      "            Bunch object with their original name.\n",
      "        \n",
      "            .. deprecated:: 0.20\n",
      "                Will be removed in version 0.22\n",
      "        \n",
      "            Parameters\n",
      "            ----------\n",
      "        \n",
      "            dataname : str\n",
      "                Name of the data set on mldata.org,\n",
      "                e.g.: \"leukemia\", \"Whistler Daily Snowfall\", etc.\n",
      "                The raw name is automatically converted to a mldata.org URL .\n",
      "        \n",
      "            target_name : optional, default: 'label'\n",
      "                Name or index of the column containing the target values.\n",
      "        \n",
      "            data_name : optional, default: 'data'\n",
      "                Name or index of the column containing the data.\n",
      "        \n",
      "            transpose_data : optional, default: True\n",
      "                If True, transpose the downloaded data array.\n",
      "        \n",
      "            data_home : optional, default: None\n",
      "                Specify another download and cache folder for the data sets. By default\n",
      "                all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "        \n",
      "            data : Bunch\n",
      "                Dictionary-like object, the interesting attributes are:\n",
      "                'data', the data to learn, 'target', the classification labels,\n",
      "                'DESCR', the full description of the dataset, and\n",
      "                'COL_NAMES', the original names of the dataset columns.\n",
      "    \n",
      "    fetch_olivetti_faces(data_home=None, shuffle=False, random_state=0, download_if_missing=True)\n",
      "        Load the Olivetti faces data-set from AT&T (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                                40\n",
      "        Samples total                         400\n",
      "        Dimensionality                       4096\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <olivetti_faces_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        shuffle : boolean, optional\n",
      "            If True the order of the dataset is shuffled to avoid having\n",
      "            images of the same person grouped.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default=0)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        An object with the following attributes:\n",
      "        \n",
      "        data : numpy array of shape (400, 4096)\n",
      "            Each row corresponds to a ravelled face image of original size\n",
      "            64 x 64 pixels.\n",
      "        \n",
      "        images : numpy array of shape (400, 64, 64)\n",
      "            Each row is a face image corresponding to one of the 40 subjects\n",
      "            of the dataset.\n",
      "        \n",
      "        target : numpy array of shape (400, )\n",
      "            Labels associated to each face image. Those labels are ranging from\n",
      "            0-39 and correspond to the Subject IDs.\n",
      "        \n",
      "        DESCR : string\n",
      "            Description of the modified Olivetti Faces Dataset.\n",
      "    \n",
      "    fetch_openml(name=None, version='active', data_id=None, data_home=None, target_column='default-target', cache=True, return_X_y=False)\n",
      "        Fetch dataset from openml by name or dataset id.\n",
      "        \n",
      "        Datasets are uniquely identified by either an integer ID or by a\n",
      "        combination of name and version (i.e. there might be multiple\n",
      "        versions of the 'iris' dataset). Please give either name or data_id\n",
      "        (not both). In case a name is given, a version can also be\n",
      "        provided.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <openml>`.\n",
      "        \n",
      "        .. note:: EXPERIMENTAL\n",
      "        \n",
      "            The API is experimental in version 0.20 (particularly the return value\n",
      "            structure), and might have small backward-incompatible changes in\n",
      "            future releases.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        name : str or None\n",
      "            String identifier of the dataset. Note that OpenML can have multiple\n",
      "            datasets with the same name.\n",
      "        \n",
      "        version : integer or 'active', default='active'\n",
      "            Version of the dataset. Can only be provided if also ``name`` is given.\n",
      "            If 'active' the oldest version that's still active is used. Since\n",
      "            there may be more than one active version of a dataset, and those\n",
      "            versions may fundamentally be different from one another, setting an\n",
      "            exact version is highly recommended.\n",
      "        \n",
      "        data_id : int or None\n",
      "            OpenML ID of the dataset. The most specific way of retrieving a\n",
      "            dataset. If data_id is not given, name (and potential version) are\n",
      "            used to obtain a dataset.\n",
      "        \n",
      "        data_home : string or None, default None\n",
      "            Specify another download and cache folder for the data sets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        target_column : string, list or None, default 'default-target'\n",
      "            Specify the column name in the data to use as target. If\n",
      "            'default-target', the standard target column a stored on the server\n",
      "            is used. If ``None``, all columns are returned as data and the\n",
      "            target is ``None``. If list (of strings), all columns with these names\n",
      "            are returned as multi-target (Note: not all scikit-learn classifiers\n",
      "            can handle all types of multi-output combinations)\n",
      "        \n",
      "        cache : boolean, default=True\n",
      "            Whether to cache downloaded datasets using joblib.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` objects.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        \n",
      "        data : Bunch\n",
      "            Dictionary-like object, with attributes:\n",
      "        \n",
      "            data : np.array or scipy.sparse.csr_matrix of floats\n",
      "                The feature matrix. Categorical features are encoded as ordinals.\n",
      "            target : np.array\n",
      "                The regression target or classification labels, if applicable.\n",
      "                Dtype is float if numeric, and object if categorical.\n",
      "            DESCR : str\n",
      "                The full description of the dataset\n",
      "            feature_names : list\n",
      "                The names of the dataset columns\n",
      "            categories : dict\n",
      "                Maps each categorical feature name to a list of values, such\n",
      "                that the value encoded as i is ith in the list.\n",
      "            details : dict\n",
      "                More metadata from OpenML\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. note:: EXPERIMENTAL\n",
      "        \n",
      "                This interface is **experimental** as at version 0.20 and\n",
      "                subsequent releases may change attributes without notice\n",
      "                (although there should only be minor changes to ``data``\n",
      "                and ``target``).\n",
      "        \n",
      "            Missing values in the 'data' are represented as NaN's. Missing values\n",
      "            in 'target' are represented as NaN's (numerical target) or None\n",
      "            (categorical target)\n",
      "    \n",
      "    fetch_rcv1(data_home=None, subset='all', download_if_missing=True, random_state=None, shuffle=False, return_X_y=False)\n",
      "        Load the RCV1 multilabel dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        Version: RCV1-v2, vectors, full sets, topics multilabels.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                               103\n",
      "        Samples total                      804414\n",
      "        Dimensionality                      47236\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <rcv1_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.17\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : string, optional\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : string, 'train', 'test', or 'all', default='all'\n",
      "            Select the dataset to load: 'train' for the training set\n",
      "            (23149 samples), 'test' for the test set (781265 samples),\n",
      "            'all' for both, with the training samples first if shuffle is False.\n",
      "            This follows the official LYRL2004 chronological split.\n",
      "        \n",
      "        download_if_missing : boolean, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : dict-like object with the following attributes:\n",
      "        \n",
      "        dataset.data : scipy csr array, dtype np.float64, shape (804414, 47236)\n",
      "            The array has 0.16% of non zero values.\n",
      "        \n",
      "        dataset.target : scipy csr array, dtype np.uint8, shape (804414, 103)\n",
      "            Each sample has a value of 1 in its categories, and 0 in others.\n",
      "            The array has 3.15% of non zero values.\n",
      "        \n",
      "        dataset.sample_id : numpy array, dtype np.uint32, shape (804414,)\n",
      "            Identification number of each sample, as ordered in dataset.data.\n",
      "        \n",
      "        dataset.target_names : numpy array, dtype object, length (103)\n",
      "            Names of each target (RCV1 topics), as ordered in dataset.target.\n",
      "        \n",
      "        dataset.DESCR : string\n",
      "            Description of the RCV1 dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_species_distributions(data_home=None, download_if_missing=True)\n",
      "        Loader for species distribution dataset from Phillips et. al. (2006)\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : optional, default: None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : optional, True by default\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        --------\n",
      "        The data is returned as a Bunch object with the following attributes:\n",
      "        \n",
      "        coverages : array, shape = [14, 1592, 1212]\n",
      "            These represent the 14 features measured at each point of the map grid.\n",
      "            The latitude/longitude values for the grid are discussed below.\n",
      "            Missing data is represented by the value -9999.\n",
      "        \n",
      "        train : record array, shape = (1624,)\n",
      "            The training points for the data.  Each point has three fields:\n",
      "        \n",
      "            - train['species'] is the species name\n",
      "            - train['dd long'] is the longitude, in degrees\n",
      "            - train['dd lat'] is the latitude, in degrees\n",
      "        \n",
      "        test : record array, shape = (620,)\n",
      "            The test points for the data.  Same format as the training data.\n",
      "        \n",
      "        Nx, Ny : integers\n",
      "            The number of longitudes (x) and latitudes (y) in the grid\n",
      "        \n",
      "        x_left_lower_corner, y_left_lower_corner : floats\n",
      "            The (x,y) position of the lower-left corner, in degrees\n",
      "        \n",
      "        grid_size : float\n",
      "            The spacing between points of the grid, in degrees\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        * `\"Maximum entropy modeling of species geographic distributions\"\n",
      "          <http://rob.schapire.net/papers/ecolmod.pdf>`_\n",
      "          S. J. Phillips, R. P. Anderson, R. E. Schapire - Ecological Modelling,\n",
      "          190:231-259, 2006.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This dataset represents the geographic distribution of species.\n",
      "        The dataset is provided by Phillips et. al. (2006).\n",
      "        \n",
      "        The two species are:\n",
      "        \n",
      "        - `\"Bradypus variegatus\"\n",
      "          <http://www.iucnredlist.org/details/3038/0>`_ ,\n",
      "          the Brown-throated Sloth.\n",
      "        \n",
      "        - `\"Microryzomys minutus\"\n",
      "          <http://www.iucnredlist.org/details/13408/0>`_ ,\n",
      "          also known as the Forest Small Rice Rat, a rodent that lives in Peru,\n",
      "          Colombia, Ecuador, Peru, and Venezuela.\n",
      "        \n",
      "        - For an example of using this dataset with scikit-learn, see\n",
      "          :ref:`examples/applications/plot_species_distribution_modeling.py\n",
      "          <sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py>`.\n",
      "    \n",
      "    get_data_home(data_home=None)\n",
      "        Return the path of the scikit-learn data dir.\n",
      "        \n",
      "        This folder is used by some large dataset loaders to avoid downloading the\n",
      "        data several times.\n",
      "        \n",
      "        By default the data dir is set to a folder named 'scikit_learn_data' in the\n",
      "        user home folder.\n",
      "        \n",
      "        Alternatively, it can be set by the 'SCIKIT_LEARN_DATA' environment\n",
      "        variable or programmatically by giving an explicit folder path. The '~'\n",
      "        symbol is expanded to the user home folder.\n",
      "        \n",
      "        If the folder does not already exist, it is automatically created.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str | None\n",
      "            The path to scikit-learn data dir.\n",
      "    \n",
      "    load_boston(return_X_y=False)\n",
      "        Load and return the boston house-prices dataset (regression).\n",
      "        \n",
      "        ==============     ==============\n",
      "        Samples total                 506\n",
      "        Dimensionality                 13\n",
      "        Features           real, positive\n",
      "        Targets             real 5. - 50.\n",
      "        ==============     ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <boston_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the regression targets,\n",
      "            'DESCR', the full description of the dataset,\n",
      "            and 'filename', the physical location of boston\n",
      "            csv dataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed a wrong data point at [445, 0].\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import load_boston\n",
      "        >>> boston = load_boston()\n",
      "        >>> print(boston.data.shape)\n",
      "        (506, 13)\n",
      "    \n",
      "    load_breast_cancer(return_X_y=False)\n",
      "        Load and return the breast cancer wisconsin dataset (classification).\n",
      "        \n",
      "        The breast cancer dataset is a classic and very easy binary classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          2\n",
      "        Samples per class    212(M),357(B)\n",
      "        Samples total                  569\n",
      "        Dimensionality                  30\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <breast_cancer_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the classification labels,\n",
      "            'target_names', the meaning of the labels, 'feature_names', the\n",
      "            meaning of the features, and 'DESCR', the full description of\n",
      "            the dataset, 'filename', the physical location of\n",
      "            breast cancer csv dataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        The copy of UCI ML Breast Cancer Wisconsin (Diagnostic) dataset is\n",
      "        downloaded from:\n",
      "        https://goo.gl/U2Uwz2\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 50, and 85, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_breast_cancer\n",
      "        >>> data = load_breast_cancer()\n",
      "        >>> data.target[[10, 50, 85]]\n",
      "        array([0, 1, 0])\n",
      "        >>> list(data.target_names)\n",
      "        ['malignant', 'benign']\n",
      "    \n",
      "    load_diabetes(return_X_y=False)\n",
      "        Load and return the diabetes dataset (regression).\n",
      "        \n",
      "        ==============      ==================\n",
      "        Samples total       442\n",
      "        Dimensionality      10\n",
      "        Features            real, -.2 < x < .2\n",
      "        Targets             integer 25 - 346\n",
      "        ==============      ==================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the regression target for each\n",
      "            sample, 'data_filename', the physical location\n",
      "            of diabetes data csv dataset, and 'target_filename', the physical\n",
      "            location of diabetes targets csv datataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_digits(n_class=10, return_X_y=False)\n",
      "        Load and return the digits dataset (classification).\n",
      "        \n",
      "        Each datapoint is a 8x8 image of a digit.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                         10\n",
      "        Samples per class             ~180\n",
      "        Samples total                 1797\n",
      "        Dimensionality                  64\n",
      "        Features             integers 0-16\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <digits_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_class : integer, between 0 and 10, optional (default=10)\n",
      "            The number of classes to return.\n",
      "        \n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'images', the images corresponding\n",
      "            to each sample, 'target', the classification labels for each\n",
      "            sample, 'target_names', the meaning of the labels, and 'DESCR',\n",
      "            the full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "        http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images::\n",
      "        \n",
      "            >>> from sklearn.datasets import load_digits\n",
      "            >>> digits = load_digits()\n",
      "            >>> print(digits.data.shape)\n",
      "            (1797, 64)\n",
      "            >>> import matplotlib.pyplot as plt #doctest: +SKIP\n",
      "            >>> plt.gray() #doctest: +SKIP\n",
      "            >>> plt.matshow(digits.images[0]) #doctest: +SKIP\n",
      "            >>> plt.show() #doctest: +SKIP\n",
      "    \n",
      "    load_files(container_path, description=None, categories=None, load_content=True, shuffle=True, encoding=None, decode_error='strict', random_state=0)\n",
      "        Load text files with categories as subfolder names.\n",
      "        \n",
      "        Individual samples are assumed to be files stored a two levels folder\n",
      "        structure such as the following:\n",
      "        \n",
      "            container_folder/\n",
      "                category_1_folder/\n",
      "                    file_1.txt\n",
      "                    file_2.txt\n",
      "                    ...\n",
      "                    file_42.txt\n",
      "                category_2_folder/\n",
      "                    file_43.txt\n",
      "                    file_44.txt\n",
      "                    ...\n",
      "        \n",
      "        The folder names are used as supervised signal label names. The individual\n",
      "        file names are not important.\n",
      "        \n",
      "        This function does not try to extract features into a numpy array or scipy\n",
      "        sparse matrix. In addition, if load_content is false it does not try to\n",
      "        load the files in memory.\n",
      "        \n",
      "        To use text files in a scikit-learn classification or clustering algorithm,\n",
      "        you will need to use the `sklearn.feature_extraction.text` module to build\n",
      "        a feature extraction transformer that suits your problem.\n",
      "        \n",
      "        If you set load_content=True, you should also specify the encoding of the\n",
      "        text using the 'encoding' parameter. For many modern text files, 'utf-8'\n",
      "        will be the correct encoding. If you leave encoding equal to None, then the\n",
      "        content will be made of bytes instead of Unicode, and you will not be able\n",
      "        to use most functions in `sklearn.feature_extraction.text`.\n",
      "        \n",
      "        Similar feature extractors should be built for other kind of unstructured\n",
      "        data input such as images, audio, video, ...\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        container_path : string or unicode\n",
      "            Path to the main folder holding one subfolder per category\n",
      "        \n",
      "        description : string or unicode, optional (default=None)\n",
      "            A paragraph describing the characteristic of the dataset: its source,\n",
      "            reference, etc.\n",
      "        \n",
      "        categories : A collection of strings or None, optional (default=None)\n",
      "            If None (default), load all the categories. If not None, list of\n",
      "            category names to load (other categories ignored).\n",
      "        \n",
      "        load_content : boolean, optional (default=True)\n",
      "            Whether to load or not the content of the different files. If true a\n",
      "            'data' attribute containing the text information is present in the data\n",
      "            structure returned. If not, a filenames attribute gives the path to the\n",
      "            files.\n",
      "        \n",
      "        shuffle : bool, optional (default=True)\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        encoding : string or None (default is None)\n",
      "            If None, do not try to decode the content of the files (e.g. for images\n",
      "            or other non-text content). If not None, encoding to use to decode text\n",
      "            files to Unicode if load_content is True.\n",
      "        \n",
      "        decode_error : {'strict', 'ignore', 'replace'}, optional\n",
      "            Instruction on what to do if a byte sequence is given to analyze that\n",
      "            contains characters not of the given `encoding`. Passed as keyword\n",
      "            argument 'errors' to bytes.decode.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default=0)\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are: either\n",
      "            data, the raw text data to learn, or 'filenames', the files\n",
      "            holding it, 'target', the classification labels (integer index),\n",
      "            'target_names', the meaning of the labels, and 'DESCR', the full\n",
      "            description of the dataset.\n",
      "    \n",
      "    load_iris(return_X_y=False)\n",
      "        Load and return the iris dataset (classification).\n",
      "        \n",
      "        The iris dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class               50\n",
      "        Samples total                  150\n",
      "        Dimensionality                   4\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <iris_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are:\n",
      "            'data', the data to learn, 'target', the classification labels,\n",
      "            'target_names', the meaning of the labels, 'feature_names', the\n",
      "            meaning of the features, 'DESCR', the full description of\n",
      "            the dataset, 'filename', the physical location of\n",
      "            iris csv dataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed two wrong data points according to Fisher's paper.\n",
      "                The new version is the same as in R, but not as in the UCI\n",
      "                Machine Learning Repository.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 25, and 50, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_iris\n",
      "        >>> data = load_iris()\n",
      "        >>> data.target[[10, 25, 50]]\n",
      "        array([0, 0, 1])\n",
      "        >>> list(data.target_names)\n",
      "        ['setosa', 'versicolor', 'virginica']\n",
      "    \n",
      "    load_linnerud(return_X_y=False)\n",
      "        Load and return the linnerud dataset (multivariate regression).\n",
      "        \n",
      "        ==============    ============================\n",
      "        Samples total     20\n",
      "        Dimensionality    3 (for both data and target)\n",
      "        Features          integer\n",
      "        Targets           integer\n",
      "        ==============    ============================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <linnerrud_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are: 'data' and\n",
      "            'targets', the two multivariate datasets, with 'data' corresponding to\n",
      "            the exercise and 'targets' corresponding to the physiological\n",
      "            measurements, as well as 'feature_names' and 'target_names'.\n",
      "            In addition, you will also have access to 'data_filename',\n",
      "            the physical location of linnerud data csv dataset, and\n",
      "            'target_filename', the physical location of\n",
      "            linnerud targets csv datataset (added in version `0.20`).\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_mlcomp(name_or_id, set_='raw', mlcomp_root=None, **kwargs)\n",
      "        DEPRECATED: since the http://mlcomp.org/ website will shut down in March 2017, the load_mlcomp function was deprecated in version 0.19 and will be removed in 0.21.\n",
      "        \n",
      "        Load a datasets as downloaded from http://mlcomp.org\n",
      "        \n",
      "            Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "            Parameters\n",
      "            ----------\n",
      "        \n",
      "            name_or_id : int or str\n",
      "                The integer id or the string name metadata of the MLComp\n",
      "                dataset to load\n",
      "        \n",
      "            set\\_ : str, default='raw'\n",
      "                Select the portion to load: 'train', 'test' or 'raw'\n",
      "        \n",
      "            mlcomp_root : str, optional\n",
      "                The filesystem path to the root folder where MLComp datasets\n",
      "                are stored, if mlcomp_root is None, the MLCOMP_DATASETS_HOME\n",
      "                environment variable is looked up instead.\n",
      "        \n",
      "            **kwargs : domain specific kwargs to be passed to the dataset loader.\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "        \n",
      "            data : Bunch\n",
      "                Dictionary-like object, the interesting attributes are:\n",
      "                'filenames', the files holding the raw to learn, 'target', the\n",
      "                classification labels (integer index), 'target_names',\n",
      "                the meaning of the labels, and 'DESCR', the full description of the\n",
      "                dataset.\n",
      "        \n",
      "            Note on the lookup process: depending on the type of name_or_id,\n",
      "            will choose between integer id lookup or metadata name lookup by\n",
      "            looking at the unzipped archives and metadata file.\n",
      "        \n",
      "            TODO: implement zip dataset loading too\n",
      "    \n",
      "    load_sample_image(image_name)\n",
      "        Load the numpy array of a single sample image\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Parameters\n",
      "        -----------\n",
      "        image_name : {`china.jpg`, `flower.jpg`}\n",
      "            The name of the sample image loaded\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        img : 3D array\n",
      "            The image as a numpy array: height x width x color\n",
      "        \n",
      "        Examples\n",
      "        ---------\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_image\n",
      "        >>> china = load_sample_image('china.jpg')   # doctest: +SKIP\n",
      "        >>> china.dtype                              # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> china.shape                              # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> flower = load_sample_image('flower.jpg') # doctest: +SKIP\n",
      "        >>> flower.dtype                             # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> flower.shape                             # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "    \n",
      "    load_sample_images()\n",
      "        Load sample images for image manipulation.\n",
      "        \n",
      "        Loads both, ``china`` and ``flower``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object with the following attributes : 'images', the\n",
      "            two sample images, 'filenames', the file names for the images, and\n",
      "            'DESCR' the full description of the dataset.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images:\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_images\n",
      "        >>> dataset = load_sample_images()     #doctest: +SKIP\n",
      "        >>> len(dataset.images)                #doctest: +SKIP\n",
      "        2\n",
      "        >>> first_img_data = dataset.images[0] #doctest: +SKIP\n",
      "        >>> first_img_data.shape               #doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> first_img_data.dtype               #doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "    \n",
      "    load_svmlight_file(f, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load datasets in the svmlight / libsvm format into sparse CSR matrix\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        This format is used as the default format for both svmlight and the\n",
      "        libsvm command line programs.\n",
      "        \n",
      "        Parsing a text based source can be expensive. When working on\n",
      "        repeatedly on the same dataset, it is recommended to wrap this\n",
      "        loader with joblib.Memory.cache to store a memmapped backup of the\n",
      "        CSR results of the first call and benefit from the near instantaneous\n",
      "        loading of memmapped structures for the subsequent calls.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        This implementation is written in Cython and is reasonably fast.\n",
      "        However, a faster API-compatible loader is also available at:\n",
      "        \n",
      "          https://github.com/mblondel/svmlight-loader\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f : {str, file-like, int}\n",
      "            (Path to) a file to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. A file-like or file descriptor will not be closed\n",
      "            by this function. A file-like object must be opened in binary mode.\n",
      "        \n",
      "        n_features : int or None\n",
      "            The number of features to use. If None, it will be inferred. This\n",
      "            argument is useful to load several files that are subsets of a\n",
      "            bigger sliced dataset: each subset might not have examples of\n",
      "            every feature, hence the inferred shape might vary from one\n",
      "            slice to another.\n",
      "            n_features is only required if ``offset`` or ``length`` are passed a\n",
      "            non-default value.\n",
      "        \n",
      "        dtype : numpy data type, default np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : boolean, optional, default False\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "        zero_based : boolean or \"auto\", optional, default \"auto\"\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no ``offset`` or ``length`` is passed.\n",
      "            If ``offset`` or ``length`` are passed, the \"auto\" mode falls back\n",
      "            to ``zero_based=True`` to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : boolean, default False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : integer, optional, default 0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : integer, optional, default -1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : scipy.sparse matrix of shape (n_samples, n_features)\n",
      "        \n",
      "        y : ndarray of shape (n_samples,), or, in the multilabel a list of\n",
      "            tuples of length n_samples.\n",
      "        \n",
      "        query_id : array of shape (n_samples,)\n",
      "           query_id for each sample. Only returned when query_id is set to\n",
      "           True.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        load_svmlight_files: similar function for loading multiple files in this\n",
      "        format, enforcing the same number of features/columns on all of them.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To use joblib.Memory to cache the svmlight file::\n",
      "        \n",
      "            from joblib import Memory\n",
      "            from sklearn.datasets import load_svmlight_file\n",
      "            mem = Memory(\"./mycache\")\n",
      "        \n",
      "            @mem.cache\n",
      "            def get_data():\n",
      "                data = load_svmlight_file(\"mysvmlightfile\")\n",
      "                return data[0], data[1]\n",
      "        \n",
      "            X, y = get_data()\n",
      "    \n",
      "    load_svmlight_files(files, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load dataset from multiple files in SVMlight format\n",
      "        \n",
      "        This function is equivalent to mapping load_svmlight_file over a list of\n",
      "        files, except that the results are concatenated into a single, flat list\n",
      "        and the samples vectors are constrained to all have the same number of\n",
      "        features.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        files : iterable over {str, file-like, int}\n",
      "            (Paths of) files to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. File-likes and file descriptors will not be\n",
      "            closed by this function. File-like objects must be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        n_features : int or None\n",
      "            The number of features to use. If None, it will be inferred from the\n",
      "            maximum column index occurring in any of the files.\n",
      "        \n",
      "            This can be set to a higher value than the actual number of features\n",
      "            in any of the input files, but setting it to a lower value will cause\n",
      "            an exception to be raised.\n",
      "        \n",
      "        dtype : numpy data type, default np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : boolean, optional\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "        zero_based : boolean or \"auto\", optional\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no offset or length is passed.\n",
      "            If offset or length are passed, the \"auto\" mode falls back\n",
      "            to zero_based=True to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : boolean, defaults to False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : integer, optional, default 0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : integer, optional, default -1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        [X1, y1, ..., Xn, yn]\n",
      "        where each (Xi, yi) pair is the result from load_svmlight_file(files[i]).\n",
      "        \n",
      "        If query_id is set to True, this will return instead [X1, y1, q1,\n",
      "        ..., Xn, yn, qn] where (Xi, yi, qi) is the result from\n",
      "        load_svmlight_file(files[i])\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When fitting a model to a matrix X_train and evaluating it against a\n",
      "        matrix X_test, it is essential that X_train and X_test have the same\n",
      "        number of features (X_train.shape[1] == X_test.shape[1]). This may not\n",
      "        be the case if you load the files individually with load_svmlight_file.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        load_svmlight_file\n",
      "    \n",
      "    load_wine(return_X_y=False)\n",
      "        Load and return the wine dataset (classification).\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        The wine dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class        [59,71,48]\n",
      "        Samples total                  178\n",
      "        Dimensionality                  13\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <wine_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : boolean, default=False.\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : Bunch\n",
      "            Dictionary-like object, the interesting attributes are: 'data', the\n",
      "            data to learn, 'target', the classification labels, 'target_names', the\n",
      "            meaning of the labels, 'feature_names', the meaning of the features,\n",
      "            and 'DESCR', the full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "        The copy of UCI ML Wine Data Set dataset is downloaded and modified to fit\n",
      "        standard format from:\n",
      "        https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 80, and 140, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_wine\n",
      "        >>> data = load_wine()\n",
      "        >>> data.target[[10, 80, 140]]\n",
      "        array([0, 1, 2])\n",
      "        >>> list(data.target_names)\n",
      "        ['class_0', 'class_1', 'class_2']\n",
      "    \n",
      "    make_biclusters(shape, n_clusters, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate an array with constant block diagonal structure for\n",
      "        biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : iterable (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : integer\n",
      "            The number of biclusters.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, optional (default=10)\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, optional (default=100)\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : array of shape (n_clusters, X.shape[0],)\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : array of shape (n_clusters, X.shape[1],)\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Dhillon, I. S. (2001, August). Co-clustering documents and\n",
      "            words using bipartite spectral graph partitioning. In Proceedings\n",
      "            of the seventh ACM SIGKDD international conference on Knowledge\n",
      "            discovery and data mining (pp. 269-274). ACM.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_checkerboard\n",
      "    \n",
      "    make_blobs(n_samples=100, n_features=2, centers=None, cluster_std=1.0, center_box=(-10.0, 10.0), shuffle=True, random_state=None)\n",
      "        Generate isotropic Gaussian blobs for clustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or array-like, optional (default=100)\n",
      "            If int, it is the total number of points equally divided among\n",
      "            clusters.\n",
      "            If array-like, each element of the sequence indicates\n",
      "            the number of samples per cluster.\n",
      "        \n",
      "        n_features : int, optional (default=2)\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        centers : int or array of shape [n_centers, n_features], optional\n",
      "            (default=None)\n",
      "            The number of centers to generate, or the fixed center locations.\n",
      "            If n_samples is an int and centers is None, 3 centers are generated.\n",
      "            If n_samples is array-like, centers must be\n",
      "            either None or an array of length equal to the length of n_samples.\n",
      "        \n",
      "        cluster_std : float or sequence of floats, optional (default=1.0)\n",
      "            The standard deviation of the clusters.\n",
      "        \n",
      "        center_box : pair of floats (min, max), optional (default=(-10.0, 10.0))\n",
      "            The bounding box for each cluster center when centers are\n",
      "            generated at random.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels for cluster membership of each sample.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets.samples_generator import make_blobs\n",
      "        >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
      "        >>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_classification: a more intricate variant\n",
      "    \n",
      "    make_checkerboard(shape, n_clusters, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate an array with block checkerboard structure for\n",
      "        biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : iterable (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : integer or iterable (n_row_clusters, n_column_clusters)\n",
      "            The number of row and column clusters.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, optional (default=10)\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, optional (default=100)\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : array of shape (n_clusters, X.shape[0],)\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : array of shape (n_clusters, X.shape[1],)\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Kluger, Y., Basri, R., Chang, J. T., & Gerstein, M. (2003).\n",
      "            Spectral biclustering of microarray data: coclustering genes\n",
      "            and conditions. Genome research, 13(4), 703-716.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_biclusters\n",
      "    \n",
      "    make_circles(n_samples=100, shuffle=True, noise=None, random_state=None, factor=0.8)\n",
      "        Make a large circle containing a smaller circle in 2d.\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The total number of points generated. If odd, the inner circle will\n",
      "            have one point more than the outer circle.\n",
      "        \n",
      "        shuffle : bool, optional (default=True)\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : double or None (default=None)\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        factor : 0 < double < 1 (default=.8)\n",
      "            Scale factor between inner and outer circle.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 2]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
      "        Generate a random n-class classification problem.\n",
      "        \n",
      "        This initially creates clusters of points normally distributed (std=1)\n",
      "        about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "        length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "        class. It introduces interdependence between these features and adds\n",
      "        various types of further noise to the data.\n",
      "        \n",
      "        Without shuffling, ``X`` horizontally stacks features in the following\n",
      "        order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "        linear combinations of the informative features, followed by ``n_repeated``\n",
      "        duplicates, drawn randomly with replacement from the informative and\n",
      "        redundant features. The remaining features are filled with random noise.\n",
      "        Thus, without shuffling, all useful features are contained in the columns\n",
      "        ``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=20)\n",
      "            The total number of features. These comprise ``n_informative``\n",
      "            informative features, ``n_redundant`` redundant features,\n",
      "            ``n_repeated`` duplicated features and\n",
      "            ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "            drawn at random.\n",
      "        \n",
      "        n_informative : int, optional (default=2)\n",
      "            The number of informative features. Each class is composed of a number\n",
      "            of gaussian clusters each located around the vertices of a hypercube\n",
      "            in a subspace of dimension ``n_informative``. For each cluster,\n",
      "            informative features are drawn independently from  N(0, 1) and then\n",
      "            randomly linearly combined within each cluster in order to add\n",
      "            covariance. The clusters are then placed on the vertices of the\n",
      "            hypercube.\n",
      "        \n",
      "        n_redundant : int, optional (default=2)\n",
      "            The number of redundant features. These features are generated as\n",
      "            random linear combinations of the informative features.\n",
      "        \n",
      "        n_repeated : int, optional (default=0)\n",
      "            The number of duplicated features, drawn randomly from the informative\n",
      "            and the redundant features.\n",
      "        \n",
      "        n_classes : int, optional (default=2)\n",
      "            The number of classes (or labels) of the classification problem.\n",
      "        \n",
      "        n_clusters_per_class : int, optional (default=2)\n",
      "            The number of clusters per class.\n",
      "        \n",
      "        weights : list of floats or None (default=None)\n",
      "            The proportions of samples assigned to each class. If None, then\n",
      "            classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "            then the last class weight is automatically inferred.\n",
      "            More than ``n_samples`` samples may be returned if the sum of\n",
      "            ``weights`` exceeds 1.\n",
      "        \n",
      "        flip_y : float, optional (default=0.01)\n",
      "            The fraction of samples whose class are randomly exchanged. Larger\n",
      "            values introduce noise in the labels and make the classification\n",
      "            task harder.\n",
      "        \n",
      "        class_sep : float, optional (default=1.0)\n",
      "            The factor multiplying the hypercube size.  Larger values spread\n",
      "            out the clusters/classes and make the classification task easier.\n",
      "        \n",
      "        hypercube : boolean, optional (default=True)\n",
      "            If True, the clusters are put on the vertices of a hypercube. If\n",
      "            False, the clusters are put on the vertices of a random polytope.\n",
      "        \n",
      "        shift : float, array of shape [n_features] or None, optional (default=0.0)\n",
      "            Shift features by the specified value. If None, then features\n",
      "            are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "        \n",
      "        scale : float, array of shape [n_features] or None, optional (default=1.0)\n",
      "            Multiply features by the specified value. If None, then features\n",
      "            are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "            happens after shifting.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels for class membership of each sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "        the \"Madelon\" dataset.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "               selection benchmark\", 2003.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_blobs: simplified variant\n",
      "        make_multilabel_classification: unrelated generator for multilabel tasks\n",
      "    \n",
      "    make_friedman1(n_samples=100, n_features=10, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #1\" regression problem\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are independent features uniformly distributed on the interval\n",
      "        [0, 1]. The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = 10 * sin(pi * X[:, 0] * X[:, 1]) + 20 * (X[:, 2] - 0.5) ** 2 + 10 * X[:, 3] + 5 * X[:, 4] + noise * N(0, 1).\n",
      "        \n",
      "        Out of the `n_features` features, only 5 are actually used to compute\n",
      "        `y`. The remaining features are independent of `y`.\n",
      "        \n",
      "        The number of features has to be >= 5.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=10)\n",
      "            The number of features. Should be at least 5.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman2(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #2\" regression problem\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = (X[:, 0] ** 2 + (X[:, 1] * X[:, 2]  - 1 / (X[:, 1] * X[:, 3])) ** 2) ** 0.5 + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 4]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman3(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #3\" regression problem\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = arctan((X[:, 1] * X[:, 2] - 1 / (X[:, 1] * X[:, 3])) / X[:, 0]) + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 4]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_gaussian_quantiles(mean=None, cov=1.0, n_samples=100, n_features=2, n_classes=3, shuffle=True, random_state=None)\n",
      "        Generate isotropic Gaussian and label samples by quantile\n",
      "        \n",
      "        This classification dataset is constructed by taking a multi-dimensional\n",
      "        standard normal distribution and defining classes separated by nested\n",
      "        concentric multi-dimensional spheres such that roughly equal numbers of\n",
      "        samples are in each class (quantiles of the :math:`\\chi^2` distribution).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean : array of shape [n_features], optional (default=None)\n",
      "            The mean of the multi-dimensional normal distribution.\n",
      "            If None then use the origin (0, 0, ...).\n",
      "        \n",
      "        cov : float, optional (default=1.)\n",
      "            The covariance matrix will be this value times the unit matrix. This\n",
      "            dataset only produces symmetric normal distributions.\n",
      "        \n",
      "        n_samples : int, optional (default=100)\n",
      "            The total number of points equally divided among classes.\n",
      "        \n",
      "        n_features : int, optional (default=2)\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        n_classes : int, optional (default=3)\n",
      "            The number of classes\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels for quantile membership of each sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The dataset is from Zhu et al [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class AdaBoost\", 2009.\n",
      "    \n",
      "    make_hastie_10_2(n_samples=12000, random_state=None)\n",
      "        Generates data for binary classification used in\n",
      "        Hastie et al. 2009, Example 10.2.\n",
      "        \n",
      "        The ten features are standard independent Gaussian and\n",
      "        the target ``y`` is defined by::\n",
      "        \n",
      "          y[i] = 1 if np.sum(X[i] ** 2) > 9.34 else -1\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=12000)\n",
      "            The number of samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 10]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical\n",
      "               Learning Ed. 2\", Springer, 2009.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_gaussian_quantiles: a generalization of this dataset approach\n",
      "    \n",
      "    make_low_rank_matrix(n_samples=100, n_features=100, effective_rank=10, tail_strength=0.5, random_state=None)\n",
      "        Generate a mostly low rank matrix with bell-shaped singular values\n",
      "        \n",
      "        Most of the variance can be explained by a bell-shaped curve of width\n",
      "        effective_rank: the low rank part of the singular values profile is::\n",
      "        \n",
      "            (1 - tail_strength) * exp(-1.0 * (i / effective_rank) ** 2)\n",
      "        \n",
      "        The remaining singular values' tail is fat, decreasing as::\n",
      "        \n",
      "            tail_strength * exp(-0.1 * i / effective_rank).\n",
      "        \n",
      "        The low rank part of the profile can be considered the structured\n",
      "        signal part of the data while the tail can be considered the noisy\n",
      "        part of the data that cannot be summarized by a low number of linear\n",
      "        components (singular vectors).\n",
      "        \n",
      "        This kind of singular profiles is often seen in practice, for instance:\n",
      "         - gray level pictures of faces\n",
      "         - TF-IDF vectors of text documents crawled from the web\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=100)\n",
      "            The number of features.\n",
      "        \n",
      "        effective_rank : int, optional (default=10)\n",
      "            The approximate number of singular vectors required to explain most of\n",
      "            the data by linear combinations.\n",
      "        \n",
      "        tail_strength : float between 0.0 and 1.0, optional (default=0.5)\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The matrix.\n",
      "    \n",
      "    make_moons(n_samples=100, shuffle=True, noise=None, random_state=None)\n",
      "        Make two interleaving half circles\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms. Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The total number of points generated.\n",
      "        \n",
      "        shuffle : bool, optional (default=True)\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : double or None (default=None)\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 2]\n",
      "            The generated samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_multilabel_classification(n_samples=100, n_features=20, n_classes=5, n_labels=2, length=50, allow_unlabeled=True, sparse=False, return_indicator='dense', return_distributions=False, random_state=None)\n",
      "        Generate a random multilabel classification problem.\n",
      "        \n",
      "        For each sample, the generative process is:\n",
      "            - pick the number of labels: n ~ Poisson(n_labels)\n",
      "            - n times, choose a class c: c ~ Multinomial(theta)\n",
      "            - pick the document length: k ~ Poisson(length)\n",
      "            - k times, choose a word: w ~ Multinomial(theta_c)\n",
      "        \n",
      "        In the above process, rejection sampling is used to make sure that\n",
      "        n is never zero or more than `n_classes`, and that the document length\n",
      "        is never zero. Likewise, we reject classes which have already been chosen.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=20)\n",
      "            The total number of features.\n",
      "        \n",
      "        n_classes : int, optional (default=5)\n",
      "            The number of classes of the classification problem.\n",
      "        \n",
      "        n_labels : int, optional (default=2)\n",
      "            The average number of labels per instance. More precisely, the number\n",
      "            of labels per sample is drawn from a Poisson distribution with\n",
      "            ``n_labels`` as its expected value, but samples are bounded (using\n",
      "            rejection sampling) by ``n_classes``, and must be nonzero if\n",
      "            ``allow_unlabeled`` is False.\n",
      "        \n",
      "        length : int, optional (default=50)\n",
      "            The sum of the features (number of words if documents) is drawn from\n",
      "            a Poisson distribution with this expected value.\n",
      "        \n",
      "        allow_unlabeled : bool, optional (default=True)\n",
      "            If ``True``, some instances might not belong to any class.\n",
      "        \n",
      "        sparse : bool, optional (default=False)\n",
      "            If ``True``, return a sparse feature matrix\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter to allow *sparse* output.\n",
      "        \n",
      "        return_indicator : 'dense' (default) | 'sparse' | False\n",
      "            If ``dense`` return ``Y`` in the dense binary indicator format. If\n",
      "            ``'sparse'`` return ``Y`` in the sparse binary indicator format.\n",
      "            ``False`` returns a list of lists of labels.\n",
      "        \n",
      "        return_distributions : bool, optional (default=False)\n",
      "            If ``True``, return the prior class probability and conditional\n",
      "            probabilities of features given classes, from which the data was\n",
      "            drawn.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The generated samples.\n",
      "        \n",
      "        Y : array or sparse CSR matrix of shape [n_samples, n_classes]\n",
      "            The label sets.\n",
      "        \n",
      "        p_c : array, shape [n_classes]\n",
      "            The probability of each class being drawn. Only returned if\n",
      "            ``return_distributions=True``.\n",
      "        \n",
      "        p_w_c : array, shape [n_features, n_classes]\n",
      "            The probability of each feature being drawn given each class.\n",
      "            Only returned if ``return_distributions=True``.\n",
      "    \n",
      "    make_regression(n_samples=100, n_features=100, n_informative=10, n_targets=1, bias=0.0, effective_rank=None, tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None)\n",
      "        Generate a random regression problem.\n",
      "        \n",
      "        The input set can either be well conditioned (by default) or have a low\n",
      "        rank-fat tail singular profile. See :func:`make_low_rank_matrix` for\n",
      "        more details.\n",
      "        \n",
      "        The output is generated by applying a (potentially biased) random linear\n",
      "        regression model with `n_informative` nonzero regressors to the previously\n",
      "        generated input and some gaussian centered noise with some adjustable\n",
      "        scale.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=100)\n",
      "            The number of features.\n",
      "        \n",
      "        n_informative : int, optional (default=10)\n",
      "            The number of informative features, i.e., the number of features used\n",
      "            to build the linear model used to generate the output.\n",
      "        \n",
      "        n_targets : int, optional (default=1)\n",
      "            The number of regression targets, i.e., the dimension of the y output\n",
      "            vector associated with a sample. By default, the output is a scalar.\n",
      "        \n",
      "        bias : float, optional (default=0.0)\n",
      "            The bias term in the underlying linear model.\n",
      "        \n",
      "        effective_rank : int or None, optional (default=None)\n",
      "            if not None:\n",
      "                The approximate number of singular vectors required to explain most\n",
      "                of the input data by linear combinations. Using this kind of\n",
      "                singular spectrum in the input allows the generator to reproduce\n",
      "                the correlations often observed in practice.\n",
      "            if None:\n",
      "                The input set is well conditioned, centered and gaussian with\n",
      "                unit variance.\n",
      "        \n",
      "        tail_strength : float between 0.0 and 1.0, optional (default=0.5)\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile if `effective_rank` is not None.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        shuffle : boolean, optional (default=True)\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        coef : boolean, optional (default=False)\n",
      "            If True, the coefficients of the underlying linear model are returned.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples] or [n_samples, n_targets]\n",
      "            The output values.\n",
      "        \n",
      "        coef : array of shape [n_features] or [n_features, n_targets], optional\n",
      "            The coefficient of the underlying linear model. It is returned only if\n",
      "            coef is True.\n",
      "    \n",
      "    make_s_curve(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate an S curve dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of sample points on the S curve.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 3]\n",
      "            The points.\n",
      "        \n",
      "        t : array of shape [n_samples]\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "    \n",
      "    make_sparse_coded_signal(n_samples, n_components, n_features, n_nonzero_coefs, random_state=None)\n",
      "        Generate a signal as a sparse combination of dictionary elements.\n",
      "        \n",
      "        Returns a matrix Y = DX, such as D is (n_features, n_components),\n",
      "        X is (n_components, n_samples) and each column of X has exactly\n",
      "        n_nonzero_coefs non-zero elements.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int\n",
      "            number of samples to generate\n",
      "        \n",
      "        n_components :  int,\n",
      "            number of components in the dictionary\n",
      "        \n",
      "        n_features : int\n",
      "            number of features of the dataset to generate\n",
      "        \n",
      "        n_nonzero_coefs : int\n",
      "            number of active (non-zero) coefficients in each sample\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : array of shape [n_features, n_samples]\n",
      "            The encoded signal (Y).\n",
      "        \n",
      "        dictionary : array of shape [n_features, n_components]\n",
      "            The dictionary with normalized components (D).\n",
      "        \n",
      "        code : array of shape [n_components, n_samples]\n",
      "            The sparse code such that each column of this matrix has exactly\n",
      "            n_nonzero_coefs non-zero items (X).\n",
      "    \n",
      "    make_sparse_spd_matrix(dim=1, alpha=0.95, norm_diag=False, smallest_coef=0.1, largest_coef=0.9, random_state=None)\n",
      "        Generate a sparse symmetric definite positive matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dim : integer, optional (default=1)\n",
      "            The size of the random matrix to generate.\n",
      "        \n",
      "        alpha : float between 0 and 1, optional (default=0.95)\n",
      "            The probability that a coefficient is zero (see notes). Larger values\n",
      "            enforce more sparsity.\n",
      "        \n",
      "        norm_diag : boolean, optional (default=False)\n",
      "            Whether to normalize the output matrix to make the leading diagonal\n",
      "            elements all 1\n",
      "        \n",
      "        smallest_coef : float between 0 and 1, optional (default=0.1)\n",
      "            The value of the smallest coefficient.\n",
      "        \n",
      "        largest_coef : float between 0 and 1, optional (default=0.9)\n",
      "            The value of the largest coefficient.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        prec : sparse matrix of shape (dim, dim)\n",
      "            The generated matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The sparsity is actually imposed on the cholesky factor of the matrix.\n",
      "        Thus alpha does not translate directly into the filling fraction of\n",
      "        the matrix itself.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_spd_matrix\n",
      "    \n",
      "    make_sparse_uncorrelated(n_samples=100, n_features=10, random_state=None)\n",
      "        Generate a random regression problem with sparse uncorrelated design\n",
      "        \n",
      "        This dataset is described in Celeux et al [1]. as::\n",
      "        \n",
      "            X ~ N(0, 1)\n",
      "            y(X) = X[:, 0] + 2 * X[:, 1] - 2 * X[:, 2] - 1.5 * X[:, 3]\n",
      "        \n",
      "        Only the first 4 features are informative. The remaining features are\n",
      "        useless.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, optional (default=10)\n",
      "            The number of features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, n_features]\n",
      "            The input samples.\n",
      "        \n",
      "        y : array of shape [n_samples]\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert,\n",
      "               \"Regularization in regression: comparing Bayesian and frequentist\n",
      "               methods in a poorly informative situation\", 2009.\n",
      "    \n",
      "    make_spd_matrix(n_dim, random_state=None)\n",
      "        Generate a random symmetric, positive-definite matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_dim : int\n",
      "            The matrix dimension.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_dim, n_dim]\n",
      "            The random symmetric, positive-definite matrix.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        make_sparse_spd_matrix\n",
      "    \n",
      "    make_swiss_roll(n_samples=100, noise=0.0, random_state=None)\n",
      "        Generate a swiss roll dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, optional (default=100)\n",
      "            The number of sample points on the S curve.\n",
      "        \n",
      "        noise : float, optional (default=0.0)\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None (default)\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : array of shape [n_samples, 3]\n",
      "            The points.\n",
      "        \n",
      "        t : array of shape [n_samples]\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is from Marsland [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] S. Marsland, \"Machine Learning: An Algorithmic Perspective\",\n",
      "               Chapter 10, 2009.\n",
      "               http://seat.massey.ac.nz/personal/s.r.marsland/Code/10/lle.py\n",
      "    \n",
      "    mldata_filename(dataname)\n",
      "        DEPRECATED: mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "        \n",
      "        Convert a raw name for a data set in a mldata.org filename.\n",
      "        \n",
      "            .. deprecated:: 0.20\n",
      "                Will be removed in version 0.22\n",
      "        \n",
      "            Parameters\n",
      "            ----------\n",
      "            dataname : str\n",
      "                Name of dataset\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "            fname : str\n",
      "                The converted dataname.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['clear_data_home', 'dump_svmlight_file', 'fetch_20newsgroup...\n",
      "\n",
      "FILE\n",
      "    /Users/juandherrera/anaconda3/lib/python3.7/site-packages/sklearn/datasets/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and targets\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "diabetes_Y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(diabetes_X, diabetes_Y, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from importlib import reload\n",
    "#reload(my_module)\n",
    "sr = my_module.SimpleRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.fit(diabetes_X, diabetes_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949.4352603839488\n",
      "152.1334841628967\n"
     ]
    }
   ],
   "source": [
    "print(sr.coef_)\n",
    "print(sr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diabetes_X, diabetes_Y, '.')\n",
    "plt.plot(diabetes_X, sr.intercept_ + sr.coef_ * diabetes_X, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the library that we're gonna use in class. It has several methods that we can use.\n",
    "# It's massive, so only load what you need.\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(diabetes_X, diabetes_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[949.43526038]\n",
      "152.1334841628967\n"
     ]
    }
   ],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We didn't have to write out module, as the linear regression method is available. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
